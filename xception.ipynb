{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6eff954d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-27 16:21:37.101853: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-07-27 16:21:37.282426: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from keras.utils import to_categorical\n",
    "from keras.datasets import cifar10\n",
    "from keras.applications.xception import Xception\n",
    "from keras.layers import Dense, Flatten, Dropout\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10e41962",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "x_train, x_test = np.array(x_train, np.float32), np.array(x_test, np.float32)\n",
    "x_train, x_test = x_train / 255., x_test / 255.\n",
    "x_train = keras.preprocessing.image.smart_resize(x_train, (71, 71))\n",
    "x_test = keras.preprocessing.image.smart_resize(x_test, (71, 71))\n",
    "y_train, y_test = to_categorical(y_train), to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6eadf2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_xception = Xception(weights='imagenet', include_top=False, input_shape=(71, 71, 3))\n",
    "model_xception.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c872bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(model_xception)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "model.compile(optimizer='adamax', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a19f67d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "1094/1094 [==============================] - 135s 122ms/step - loss: 0.1791 - accuracy: 0.6705 - val_loss: 0.1531 - val_accuracy: 0.7007\n",
      "Epoch 2/15\n",
      "1094/1094 [==============================] - 138s 126ms/step - loss: 0.1338 - accuracy: 0.7372 - val_loss: 0.1426 - val_accuracy: 0.7141\n",
      "Epoch 3/15\n",
      "1094/1094 [==============================] - 138s 126ms/step - loss: 0.1154 - accuracy: 0.7727 - val_loss: 0.1425 - val_accuracy: 0.7176\n",
      "Epoch 4/15\n",
      "1094/1094 [==============================] - 139s 127ms/step - loss: 0.1012 - accuracy: 0.8022 - val_loss: 0.1452 - val_accuracy: 0.7179\n",
      "Epoch 5/15\n",
      "1094/1094 [==============================] - 139s 127ms/step - loss: 0.0883 - accuracy: 0.8342 - val_loss: 0.1424 - val_accuracy: 0.7282\n",
      "Epoch 6/15\n",
      "1094/1094 [==============================] - 140s 128ms/step - loss: 0.0766 - accuracy: 0.8638 - val_loss: 0.1493 - val_accuracy: 0.7215\n",
      "Epoch 7/15\n",
      "1094/1094 [==============================] - 140s 128ms/step - loss: 0.0658 - accuracy: 0.8888 - val_loss: 0.1534 - val_accuracy: 0.7259\n",
      "Epoch 8/15\n",
      "1094/1094 [==============================] - 139s 127ms/step - loss: 0.0559 - accuracy: 0.9130 - val_loss: 0.1566 - val_accuracy: 0.7341\n",
      "Epoch 9/15\n",
      "1094/1094 [==============================] - 139s 127ms/step - loss: 0.0469 - accuracy: 0.9340 - val_loss: 0.1637 - val_accuracy: 0.7261\n",
      "Epoch 10/15\n",
      "1094/1094 [==============================] - 139s 127ms/step - loss: 0.0387 - accuracy: 0.9512 - val_loss: 0.1747 - val_accuracy: 0.7277\n",
      "Epoch 11/15\n",
      "1094/1094 [==============================] - 140s 128ms/step - loss: 0.0320 - accuracy: 0.9647 - val_loss: 0.1783 - val_accuracy: 0.7300\n",
      "Epoch 12/15\n",
      "1094/1094 [==============================] - 139s 127ms/step - loss: 0.0257 - accuracy: 0.9765 - val_loss: 0.1910 - val_accuracy: 0.7233\n",
      "Epoch 13/15\n",
      "1094/1094 [==============================] - 139s 127ms/step - loss: 0.0211 - accuracy: 0.9827 - val_loss: 0.2054 - val_accuracy: 0.7245\n",
      "Epoch 14/15\n",
      "1094/1094 [==============================] - 140s 128ms/step - loss: 0.0169 - accuracy: 0.9888 - val_loss: 0.2118 - val_accuracy: 0.7300\n",
      "Epoch 15/15\n",
      "1094/1094 [==============================] - 148s 135ms/step - loss: 0.0134 - accuracy: 0.9923 - val_loss: 0.2198 - val_accuracy: 0.7242\n"
     ]
    }
   ],
   "source": [
    "result = model.fit(x_train, y_train, batch_size=32, epochs=15, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26d56e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
